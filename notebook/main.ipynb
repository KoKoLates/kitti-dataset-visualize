{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stereo Visual Odometry\n",
    "This notebook apply stereo depth estimation and multiple view geometry to track vehicle position through a sequencee of the images from kitti dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DatasetHandler(object):\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get the ground truth trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = pd.read_csv(\"../dataset/poses/00.txt\", delimiter=' ', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix}\n",
    "    x_w \\\\ y_w \\\\ z_w\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = plt.imread()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Projection and Calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = pd.read_csv('', delimiter=' ', header=None, index_col=0)\n",
    "calib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In calibration file, we can obtain four `3x4` projection matrices for four position camera: `p0`, `p1`, `p2` and `p3`. And we can also obtain the transformation matrix for the LiDAR that denoted as `Tr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P0 is the left grayscale camera\n",
    "import numpy as np\n",
    "\n",
    "p0: np.ndarray = np.array(calib.loc['P0:']).reshape((3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A projection matrix project three dimensional cooridnates in the global coordinates (world coordinates) onto two dimensional image plane (pixel coordinate)\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    u \\\\ v \\\\ 1\n",
    "\\end{bmatrix} = \\frac{1}{\\lambda}P\n",
    "\\begin{bmatrix}\n",
    "    x_w \\\\ y_w\\\\ z_w\\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $\\lambda$ is known as the scale, which is the depth to the point along z-axis from the camera. The projection matrix `P` is the dot product of intrinsic matrix and extrinsic matrix. The intrinsic matrix `K` that describe the focal length and optical center parameters of camera, and the extrinsic matrix is the augmented matrix of rotation matrix and translation vector that describe the transformation between world coordinates and camera coordinates\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    u \\\\ v \\\\ 1\n",
    "\\end{bmatrix} = \\frac{1}{\\lambda}P\n",
    "\\begin{bmatrix}\n",
    "    x_w \\\\ y_w\\\\ z_w\\\\ 1\n",
    "\\end{bmatrix} = \\frac{1}{\\lambda}K[R|t]\n",
    "\\begin{bmatrix}\n",
    "    x_w \\\\ y_w\\\\ z_w\\\\ 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1: np.ndarray = np.array(calib.loc['P1:']).reshape((3, 4))\n",
    "\n",
    "import cv2\n",
    "k, r, t, _, _, _, _ = cv2.decomposeProjectionMatrix(p1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Handler\n",
    "Implement the dataset handler to manipulate the dataset from files, and make it more accessible to complete our mission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetHandler(object):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def _reset(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo Depth Estimation\n",
    "\n",
    "\n",
    "\n",
    "<div align='center'>\n",
    "    <img src=\"../assets/stereo.png\" width='300' alt='stereo' />\n",
    "</div>\n",
    "\n",
    "With similar triangles, we can derive as following:\n",
    "\n",
    "$$\n",
    "\\frac{Z}{f}=\\frac{X}{x_L}, \\frac{Z}{f}=\\frac{X-b}{x_R}\n",
    "$$\n",
    "\n",
    "and we define **disparity `d`** as the difference between $x_L$ amd $x_R$, which means the difference in horizontal pixel location of the point projected onto left and right image plane.\n",
    "\n",
    "$$\n",
    "d = (x_L - x_R)\n",
    "$$\n",
    "\n",
    "Thus, we can get\n",
    "\n",
    "$$\n",
    "fb=Zd \\rightarrow Z=\\frac{fb}d\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def compute_disparity_map(\n",
    "    image_l: np.ndarray,\n",
    "    image_r: np.ndarray,\n",
    "    matcher: str = 'bm',\n",
    "    rgb_map: bool = False,\n",
    "    verbose: bool = False,\n",
    ") -> np.ndarray | None:\n",
    "    if matcher not in ('bm', 'sgbm'):\n",
    "        raise ValueError('matcher type is not in list.')\n",
    "    \n",
    "    if matcher == 'bm':\n",
    "        matcher = cv2.StereoBM_create()\n",
    "    else:\n",
    "        print('sgbm')\n",
    "\n",
    "    if rgb_map:\n",
    "        l = cv2.cvtColor(image_l, cv2.COLOR_BGR2GRAY)\n",
    "        r = cv2.cvtColor(image_r, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ## computing matching\n",
    "    import datetime\n",
    "    t0 = datetime.datetime.now()\n",
    "    disp = matcher.compute(l, r).astype(np.float32) / 16\n",
    "    t1 = datetime.datetime.now()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Time to compute disparity map with stereo{matcher}: {t1 -t0}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LiDAR Dataset Process\n",
    "Process the LiDAR data from the dataset, which could be used for depth estimation and odometry correction later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Matching\n",
    "Extract the feature from image and matching between each frame to find the transformation relationship in camera poses between a sequences of frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Odometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VO(object):\n",
    "    def __init__(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalcError(object):\n",
    "    def __init__(self, gt: np.ndarray, est: np.ndarray) -> None:\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _mse(gt: np.ndarray, est: np.ndarray) -> np.float64:\n",
    "        n: int = est.shape[0]\n",
    "        se = np.power(np.sqrt(\n",
    "            np.power(gt[n, 0, 3] - est[:, 0, 3], 2) +  \n",
    "            np.power(gt[n, 1, 3] - est[:, 1, 3], 2) +\n",
    "            np.power(gt[n, 2, 3] - est[:, 2, 3], 2) \n",
    "        ), 2)\n",
    "        mse = np.mean(se)\n",
    "        return mse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
