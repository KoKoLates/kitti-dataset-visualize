{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Odometry\n",
    "This notebook apply stereo depth estimation and multiple view geometry to track vehicle position through a sequencee of the images from kitti dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from dataclasses import dataclass\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Optional\n",
    "\n",
    "\n",
    "class DatasetHandler(object):\n",
    "    def __init__(self) -> None:\n",
    "        self.l_dr = os.getenv(\"IMG_L_DIR\")\n",
    "        self.r_dr = os.getenv(\"IMG_R_DIR\")\n",
    "        self.l_ls = sorted(os.listdir(self.l_dr), key=lambda x: int(x.split('.')[0]))\n",
    "        self.r_ls = sorted(os.listdir(self.r_dr), key=lambda x: int(x.split('.')[0]))\n",
    "        self._reset_frame()\n",
    "        \n",
    "        # Ground truth\n",
    "        p = pd.read_csv(os.getenv(\"POSES_FILE\"), delimiter=' ', header=None)\n",
    "        self.gt: np.ndarray = p.values.reshape((-1, 3, 4))\n",
    "\n",
    "        # Camera intrinsic matrix, and lidar transform matrix\n",
    "        c = pd.read_csv(os.getenv(\"CALIB_FILE\"), delimiter=' ', header=None, index_col=0)\n",
    "        self.K0, self.K1, self.Tr = map(\n",
    "            lambda x: np.array(c.loc[x, :]).reshape((3, 4)), ('P0:', 'P1:', 'Tr:')\n",
    "        )\n",
    "\n",
    "        self.frame_num: int = len(self.l_ls)\n",
    "        self.frame_idx: int = 1\n",
    "        self.l_image_1: cv2.Mat = next(self.l_images)\n",
    "\n",
    "\n",
    "    def frame(self) -> tuple:\n",
    "        pass\n",
    "\n",
    "    def next_frame(self) -> None:\n",
    "        self.l_image_0 = self.l_image_1\n",
    "        self.r_image_0 = next(self.r_images)\n",
    "        self.l_image_1 = next(self.l_images)\n",
    "\n",
    "        self.lidar_t = next(self.lidar)\n",
    "    \n",
    "    def stop(self) -> bool:\n",
    "        return self.frame_num == self.frame_idx\n",
    "    \n",
    "    def imsize(self) -> tuple[int, int]:\n",
    "        return self.l_image_1.shape[0], self.l_image_1.shape[1]\n",
    "\n",
    "    def _reset_frame(self) -> None:\n",
    "        self.l_images: Iterator[cv2.Mat] = (\n",
    "            cv2.imread(os.path.join(self.l_dr, file)) \n",
    "            for file in self.l_ls\n",
    "        )\n",
    "        self.r_images: Iterator[cv2.Mat] = (\n",
    "            cv2.imread(os.path.join(self.r_dr, file)) \n",
    "            for file in self.r_ls\n",
    "        )\n",
    "        self.lidar: Iterator[np.ndarray] = (\n",
    "            np.fromfile(os.path.join(\"\", file))\n",
    "            for file in self._ls\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config(object):\n",
    "    lidar_correct: bool\n",
    "    stereo_matcher: Optional[str] = None\n",
    "\n",
    "    P0: np.ndarray\n",
    "    P1: np.ndarray\n",
    "    Tr: np.ndarray\n",
    "\n",
    "    feature_detector: str = 'orb'\n",
    "    feature_matcher: str = 'bf'\n",
    "    matching_threshold: Optional[float] = None\n",
    "\n",
    "\n",
    "class VisualOdometry(object):\n",
    "    def __init__(self, config: Config) -> None:\n",
    "        self.config: Config = config\n",
    "\n",
    "        ## camera coefficient\n",
    "        self.P0 = self.config.P0\n",
    "        self.P1 = self.config.P1\n",
    "        self.Tr = self.config.Tr\n",
    "        self.K0, self.R0, self.t0, *_ = cv2.decomposeProjectionMatrix(self.P0)\n",
    "        self.K1, self.R1, self.t1, *_ = cv2.decomposeProjectionMatrix(self.P1)\n",
    "        self.f = self.K0[0, 0]\n",
    "        self.b = self.t1[0] - self.t0[0]\n",
    "        self.ih, self.iw = 0, 0\n",
    "        self.cx, self.cy = self.K0[0, 2], self.K0[1, 2]\n",
    "        self.fx, self.fy = self.K0[0, 0], self.K0[1, 1]\n",
    "\n",
    "        ## stereo matcher\n",
    "        self._stereo_matcher: Optional[cv2.StereoBM | cv2.StereoSGBM] = None\n",
    "        if self.config.stereo_matcher == 'sgbm':\n",
    "            self._stereo_matcher = cv2.StereoSGBM(\n",
    "                numDisparities=96,\n",
    "                minDisparity=0,\n",
    "                blockSize=11,\n",
    "                P1 = 864, P2 = 3456,\n",
    "                mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
    "            )\n",
    "        elif self.config.stereo_matcher == 'bm':\n",
    "            self._stereo_matcher = cv2.StereoBM(numDisparities=96, blockSize=11)\n",
    "\n",
    "        ## feature detection and matching\n",
    "        det_map: dict[str, cv2.ORB | cv2.SIFT] = {\n",
    "            'orb': cv2.ORB.create,\n",
    "            'sift': cv2.SIFT.create, \n",
    "        }\n",
    "        self._feature_detector: cv2.SIFT | cv2.ORB = det_map[self.config.feature_detector]()\n",
    "\n",
    "        if self.config.feature_matcher == 'bf':\n",
    "            self._feature_matcher = cv2.BFMatcher.create(\n",
    "                cv2.NORM_L2 if self.config.feature_detector == 'sift' else cv2.NORM_HAMMING2,\n",
    "                crossCheck=False\n",
    "            )\n",
    "        else:\n",
    "            self._feature_matcher = cv2.FlannBasedMatcher(\n",
    "                dict(algorithm=1, trees=5), \n",
    "                dict(checks=50)\n",
    "            )\n",
    "        self.threshold = self.config.matching_threshold\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        image_l0: np.ndarray,\n",
    "        image_r0: np.ndarray,\n",
    "        image_l1: np.ndarray,\n",
    "        point_clould: Optional[np.ndarray] = None\n",
    "    ) -> None:\n",
    "        \n",
    "        depth: Optional[np.ndarray] = None\n",
    "        if self._stereo_matcher is not None:\n",
    "            depth = self._depth_estimate(image_l0, image_r0, point_clould)\n",
    "\n",
    "        ## feature extraction and matching\n",
    "        kp0, des0 = self._feature_detector.detectAndCompute(image_l0, None)\n",
    "        kp1, des1 = self._feature_detector.detectAndCompute(image_l1, None)\n",
    "\n",
    "        m = self._features_matching(des0, des1)\n",
    "        R, t = self._motion_estimate(kp0, kp1, m, depth)\n",
    "\n",
    "        \n",
    "    def _depth_estimate(\n",
    "        self, \n",
    "        image_l0: np.ndarray,\n",
    "        image_r0: np.ndarray,\n",
    "        point_clould: Optional[np.ndarray] = None\n",
    "    ) -> np.ndarray:\n",
    "        disp = self._stereo_matcher.compute(image_l0, image_r0).astype(np.float32) / 16\n",
    "        disp = np.where((disp == 0.0) | (disp == -1.0), 0.1, disp)\n",
    "        \n",
    "        depth = (self.f * self.b) / disp\n",
    "        if not point_clould or not self.config.lidar_correct:\n",
    "            return depth\n",
    "        \n",
    "        ## lidar depth correction\n",
    "        pcl = point_clould[point_clould[:, 0] > 0]\n",
    "        pcl = np.hstack([pcl[:, :3], np.ones(pcl.shape[0]).reshape((-1, 1))])\n",
    "        cam = self.Tr @ pcl.T\n",
    "        cam = cam[:, cam[2] > 0]\n",
    "        dep = cam[2].copy()\n",
    "        cam /= cam[2]\n",
    "        cam = np.vstack([cam, np.ones(cam.shape[1])])\n",
    "\n",
    "        project = self.P0 @ cam\n",
    "        pixel_coord = project.T.round(0)[:, :2].astype(np.int32)\n",
    "\n",
    "        indices = np.where(\n",
    "            (pixel_coord[:, 0] < self.iw) &\n",
    "            (pixel_coord[:, 1] < self.ih) &\n",
    "            (pixel_coord[:, 0] >= 0) &\n",
    "            (pixel_coord[:, 1] >= 0)\n",
    "        )\n",
    "        pixel_coord = pixel_coord[indices]\n",
    "        dep = dep[indices]\n",
    "\n",
    "        depth_map = np.zeros((self.ih, self.iw))\n",
    "        for i, (u, v) in enumerate(pixel_coord):\n",
    "            if u < 0 or u >= self.iw or v < 0 or v > self.ih:\n",
    "                continue\n",
    "            depth_map[v, u] = depth[i]\n",
    "    \n",
    "        depth_map[depth_map == 0.0] = 3000\n",
    "\n",
    "        indices = np.where(depth_map < 3000)\n",
    "        depth[indices] = depth_map[indices]\n",
    "    \n",
    "        return depth\n",
    "\n",
    "    def _features_matching(\n",
    "        self,\n",
    "        des1: np.ndarray,\n",
    "        des2: np.ndarray,\n",
    "    ) -> list[cv2.DMatch]:\n",
    "        matches = self._feature_matcher.knnMatch(des1, des2, 2)\n",
    "        matches = sorted(matches, key=lambda x: x[0].distance)\n",
    "\n",
    "        return [\n",
    "            m for m, n in matches \n",
    "            if not self.threshold or m.distance <= n.distance * self.threshold\n",
    "        ]\n",
    "    \n",
    "    def _motion_estimate(\n",
    "        self,\n",
    "        kp1: list[cv2.KeyPoint],\n",
    "        kp2: list[cv2.KeyPoint],\n",
    "        matches: list[cv2.DMatch],\n",
    "        depth: Optional[np.ndarray] = None,\n",
    "        depth_max: int = 3000\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        R: np.ndarray = np.eye(3)\n",
    "        t: np.ndarray = np.zeros((3, 1))\n",
    "\n",
    "        pts_1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "        pts_2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "\n",
    "        if depth is None: # apply essential matrix decomposition, scale ambiguous\n",
    "            E = cv2.findEssentialMat(pts_1, pts_2, self.K0)\n",
    "            _, R, t, _ = cv2.recoverPose(E, pts_1, pts_2, self.K0)\n",
    "            return R, t\n",
    "        \n",
    "        ## convert points in image1 into world coordinate with camera parameter and depth information,\n",
    "        ## and apply PnP algorithm with RANSAC for robustness to outlier\n",
    "        pts_w = np.zeros((0, 3))\n",
    "        remove_idx: list[int] = []\n",
    "\n",
    "        for i, (u, v) in enumerate(pts_1):\n",
    "            z = depth[int(v), int[u]]\n",
    "            if z > depth_max:\n",
    "                remove_idx.append(i)\n",
    "                continue\n",
    "\n",
    "            x = z * (u - self.cx) / self.fx\n",
    "            y = z * (u - self.cy) / self.fy\n",
    "            pts_w = np.vstack([pts_w, np.array([x, y, z])])\n",
    "\n",
    "        pts_2 = np.delete(pts_2, remove_idx, 0)\n",
    "        _, R_vec, t, _ = cv2.solvePnPRansac(pts_w, pts_2, self.K0, None)\n",
    "        R = cv2.Rodrigues(R_vec)[0]\n",
    "        return R, t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def pipeline(config) -> VisualOdometry:\n",
    "    \n",
    "    handler = DatasetHandler()\n",
    "    h, w = handler.imsize()\n",
    "    \n",
    "    vo = VisualOdometry()\n",
    "    for _ in tqdm(range(handler.frame_num - 1)):\n",
    "        image0, image1, image2, pc = handler.next_frame()\n",
    "\n",
    "        vo.update(image0, image1, image2, pc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
